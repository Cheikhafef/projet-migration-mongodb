{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10541e6-9850-46bc-ad1a-02bc7ec6e874",
   "metadata": {},
   "source": [
    "## Pipeline de Transformation & Fusion des Données Météo\n",
    "Ce script constitue le cœur du pipeline : il normalise les données issues des stations personnelles, enrichit chaque mesure avec des métadonnées, intègre les données InfoClimat, fusionne les deux sources en comblant les valeurs manquantes, puis génère un fichier final prêt pour ingestion dans MongoDB.\n",
    "\n",
    " 1. Métadonnées des stations personnelles\n",
    "Deux stations personnelles sont définies :\n",
    "\n",
    "ILAMAD25 → La Madeleine (FR)\n",
    "\n",
    "IICHTE19 → Ichtegem (BE)\n",
    "\n",
    "Chaque station possède : nom, coordonnées, altitude, matériel, logiciel et type de source.\n",
    "\n",
    "2. Fonctions utilitaires\n",
    "Le script inclut plusieurs fonctions essentielles :\n",
    "   - Chargement & sauvegarde JSON\n",
    "   - Conversion sécurisée\n",
    "   - Normalisation du schéma\n",
    "   - Enrichissement des mesures\n",
    "   - Test d’intégrité\n",
    "\n",
    "3. Pipeline stations personnelles\n",
    "process_personal_station(input_file, station_id) :\n",
    "  - Charge le JSON brut\n",
    "  - Normalise chaque mesure\n",
    "  - Enrichit avec les métadonnées station\n",
    "  - Ajoute au tableau global ALL_DOCS\n",
    "\n",
    "4. Pipeline InfoClimat\n",
    "process_infoclimat(input_file) :\n",
    "  - Ajoute dynamiquement les stations InfoClimat au dictionnaire STATIONS_META\n",
    "  - Normalise toutes les mesures horaires\n",
    "  - Enrichit avec les métadonnées InfoClimat\n",
    "  - Retourne une liste complète de documents prêts à fusionner\n",
    "\n",
    "5. Fusion des données InfoClimat → Stations personnelles\n",
    "merge_infoclimat(personal_docs, infoclimat_docs, mapping) :\n",
    " - Associe chaque station personnelle à une station InfoClimat via un mapping\n",
    " - Pour chaque mesure personnelle :\n",
    " - recherche la mesure InfoClimat la plus proche dans le temps\n",
    " - remplace uniquement les champs manquants ou nuls\n",
    " - Conserve l’intégrité des données d’origine\n",
    "\n",
    "6. Exécution principale\n",
    "Le bloc MAIN :\n",
    " - Charge et traite les deux stations personnelles\n",
    " - Charge et traite InfoClimat\n",
    " - Applique le mapping :\n",
    "        * ILAMAD25 → 07015\n",
    "        * IICHTE19 → 07016\n",
    " - Fusionne les données\n",
    " - Exécute les tests d’intégrité\n",
    " - Sauvegarde le fichier final :\n",
    "output/final_mongo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de0bd33-f3c4-4608-8d64-73126c9a16a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PIPELINE DE TRANSFORMATION & FUSION =====\n",
      "=== échantillon IICHTE19 (perso) ===\n",
      "{'record_id': 'ef17bc9731094d35a3469b0afd8ad446', 'station_id': 'IICHTE19', 'name': 'WeerstationBS', 'city': 'Ichtegem', 'location': {'latitude': 51.092, 'longitude': 2.999, 'elevation': 15}, 'hardware': 'other', 'software': 'EasyWeatherV1.6.6', 'source': 'Personal Station', 'timestamp': '2024-10-01T00:04:00+00:00', 'temperature': 56.8, 'humidity': 87.0, 'pressure': 29.48, 'wind_speed': 8.2, 'wind_gust': 10.4, 'rain_rate': 0.0, 'rain_total': 0.0, 'uv': 0.0, 'solar': 0.0}\n",
      "=== Stations InfoClimat disponibles ===\n",
      "['00052', '000R5', '07015', 'STATIC0010']\n",
      "=== Exemple données InfoClimat pour 07016 ===\n",
      "{'record_id': '903adc1eb5e04500989463d800f5466a', 'station_id': '07015', 'name': 'Lille-Lesquin', 'city': 'Lille-Lesquin', 'location': {'latitude': 50.575, 'longitude': 3.092, 'elevation': 47}, 'hardware': 'professional', 'software': 'InfoClimat', 'source': 'InfoClimat', 'timestamp': '2024-10-05T00:00:00+00:00', 'temperature': 7.6, 'humidity': 89.0, 'pressure': 1020.7, 'wind_speed': 3.6, 'wind_gust': 7.2, 'rain_rate': 0.0, 'rain_total': 0.0, 'uv': None, 'solar': None}\n",
      "\n",
      "===== TEST → FINAL JSON FUSIONNÉ =====\n",
      "Documents : 3807\n",
      "Valeurs manquantes :\n",
      "RAS\n",
      "Doublons détectés : 0\n",
      "\n",
      " FINI — 3807 documents prêts pour MongoDB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from uuid import uuid4\n",
    "import math\n",
    "from datetime import datetime\n",
    "# =====================================================\n",
    "# MÉTADONNÉES STATIONS PERSONNELLES\n",
    "# =====================================================\n",
    "STATIONS_META = {\n",
    "    \"ILAMAD25\": {\n",
    "        \"name\": \"La Madeleine\",\n",
    "        \"lat\": 50.659,\n",
    "        \"lon\": 3.07,\n",
    "        \"elevation\": 23,\n",
    "        \"city\": \"La Madeleine\",\n",
    "        \"hardware\": \"other\",\n",
    "        \"software\": \"EasyWeatherPro_V5.1.6\",\n",
    "        \"source\": \"Personal Station\"\n",
    "    },\n",
    "    \"IICHTE19\": {\n",
    "        \"name\": \"WeerstationBS\",\n",
    "        \"lat\": 51.092,\n",
    "        \"lon\": 2.999,\n",
    "        \"elevation\": 15,\n",
    "        \"city\": \"Ichtegem\",\n",
    "        \"hardware\": \"other\",\n",
    "        \"software\": \"EasyWeatherV1.6.6\",\n",
    "        \"source\": \"Personal Station\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# =====================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# =====================================================\n",
    "def is_missing(x):\n",
    "    return x is None or (isinstance(x, float) and math.isnan(x))\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path, content):\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(content, f, indent=4, ensure_ascii=False)\n",
    "def to_float(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(v, (int, float)):\n",
    "        return float(v)\n",
    "\n",
    "    if isinstance(v, str):\n",
    "        # extraire le premier nombre (gère \"0.01 in\", \"65.0 °F\", \"72 %\")\n",
    "        match = re.search(r\"-?\\d+(\\.\\d+)?\", v)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "#def to_float(v):\n",
    " #   try:\n",
    "  #      return float(v)\n",
    "   # except:\n",
    "    #    return None\n",
    "\n",
    "\n",
    "def parse_personal_datetime(date_str, time_str):\n",
    "    \"\"\"\n",
    "    Convertit '071024' + '14:44:00' → '2024-10-07T14:44:00Z'\n",
    "    Format perso = DDMMYY\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dt = datetime.strptime(date_str + \" \" + time_str, \"%d%m%y %H:%M:%S\")\n",
    "        return dt.isoformat() + \"Z\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_measure(record):\n",
    "    if not isinstance(record, dict):\n",
    "        return {\n",
    "            \"timestamp\": None,\n",
    "            \"temperature\": None,\n",
    "            \"humidity\": None,\n",
    "            \"pressure\": None,\n",
    "            \"wind_speed\": None,\n",
    "            \"wind_gust\": None,\n",
    "            \"rain_rate\": 0.0,\n",
    "            \"rain_total\": 0.0,\n",
    "            \"uv\": None,\n",
    "            \"solar\": None\n",
    "        }\n",
    "\n",
    "    def get(*keys):\n",
    "        for k in keys:\n",
    "            if k in record and record[k] not in [\"\", None, \" \"]:\n",
    "                return record[k]\n",
    "        return None\n",
    "\n",
    "    # ====== CORRECTION DATE / TIME ======\n",
    "    ts = None\n",
    "\n",
    "    date_str = record.get(\"date\")      # ex: \"071024\"\n",
    "    time_str = record.get(\"time\")      # ex: \"14:44:00\"\n",
    "\n",
    "    if date_str and time_str and len(date_str) == 6:\n",
    "        day = date_str[:2]\n",
    "        month = date_str[2:4]\n",
    "        year = \"20\" + date_str[4:6]\n",
    "\n",
    "        ts_str = f\"{year}-{month}-{day} {time_str}\"\n",
    "        ts = pd.to_datetime(ts_str, utc=True, errors=\"coerce\")\n",
    "\n",
    "    # fallback (InfoClimat)\n",
    "    if ts is None:\n",
    "        raw_ts = get(\"timestamp\", \"datetime\", \"dh_utc\")\n",
    "        if raw_ts:\n",
    "            ts = pd.to_datetime(raw_ts, utc=True, errors=\"coerce\")\n",
    "\n",
    "    ts = ts.isoformat() if ts is not None and not pd.isna(ts) else None\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": ts,\n",
    "        \"temperature\": to_float(get(\"temperature\", \"temp\")),\n",
    "        \"humidity\": to_float(get(\"humidity\", \"humidite\")),\n",
    "        \"pressure\": to_float(get(\"pressure\", \"pression\")),\n",
    "        \"wind_speed\": to_float(get(\"wind_speed\", \"vent_moyen\")),\n",
    "        \"wind_gust\": to_float(get(\"wind_gust\", \"vent_rafales\")),\n",
    "        \"rain_rate\": to_float(get(\"pluie_1h\", \"precip_1h\", \"precip_rate\")) or 0.0,\n",
    "        \"rain_total\": to_float(get(\"pluie_3h\", \"precip_3h\", \"precip_accum\")) or 0.0,\n",
    "        \"uv\": to_float(get(\"uv\")),\n",
    "        \"solar\": to_float(get(\"solar\"))\n",
    "    }\n",
    "\n",
    "def enrich_measure(station_id, rec):\n",
    "    \"\"\"Ajout des métadonnées station + record_id\"\"\"\n",
    "    meta = STATIONS_META.get(station_id, {})\n",
    "    return {\n",
    "        \"record_id\": uuid4().hex,\n",
    "        \"station_id\": station_id,\n",
    "        \"name\": meta.get(\"name\"),\n",
    "        \"city\": meta.get(\"city\"),\n",
    "        \"location\": {\n",
    "            \"latitude\": meta.get(\"lat\"),\n",
    "            \"longitude\": meta.get(\"lon\"),\n",
    "            \"elevation\": meta.get(\"elevation\")\n",
    "        },\n",
    "        \"hardware\": meta.get(\"hardware\"),\n",
    "        \"software\": meta.get(\"software\"),\n",
    "        \"source\": meta.get(\"source\"),\n",
    "        \"timestamp\": rec[\"timestamp\"],\n",
    "        \"temperature\": rec[\"temperature\"],\n",
    "        \"humidity\": rec[\"humidity\"],\n",
    "        \"pressure\": rec[\"pressure\"],\n",
    "        \"wind_speed\": rec[\"wind_speed\"],\n",
    "        \"wind_gust\": rec[\"wind_gust\"],\n",
    "        \"rain_rate\": rec[\"rain_rate\"],\n",
    "        \"rain_total\": rec[\"rain_total\"],\n",
    "        \"uv\": rec[\"uv\"],\n",
    "        \"solar\": rec[\"solar\"]\n",
    "    }\n",
    "\n",
    "def test_integrity(records, label):\n",
    "    \"\"\"Test automatique de l'intégrité des données\"\"\"\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"\\n===== TEST → {label} =====\")\n",
    "    print(f\"Documents : {len(df)}\")\n",
    "    if df.empty:\n",
    "        return\n",
    "    missing = df.isna().sum()\n",
    "    print(\"Valeurs manquantes :\")\n",
    "    print(missing[missing > 0] if missing.sum() else \"RAS\")\n",
    "    if \"station_id\" in df.columns and \"timestamp\" in df.columns:\n",
    "        dup = df.duplicated([\"station_id\", \"timestamp\"]).sum()\n",
    "        print(f\"Doublons détectés : {dup}\")\n",
    "\n",
    "\n",
    "def is_missing(x):\n",
    "    return x is None or (isinstance(x, float) and math.isnan(x))\n",
    "\n",
    "#Fusionne les valeurs InfoClimat pour remplacer les null des stations perso.\n",
    "   # On cherche la mesure InfoClimat la plus proche de chaque timestamp perso.\n",
    "\n",
    "def merge_infoclimat(personal_docs, infoclimat_docs, mapping):\n",
    "    # Index InfoClimat par station\n",
    "    ic_index = {}\n",
    "    for ic in infoclimat_docs:\n",
    "        ic_station = ic.get(\"station_id\")\n",
    "        if ic_station:\n",
    "            ic_index.setdefault(ic_station, []).append(ic)\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for r in personal_docs:\n",
    "        station = r.get(\"station_id\")\n",
    "        ic_station = mapping.get(station)\n",
    "\n",
    "        # Pas de station InfoClimat correspondante\n",
    "        if not ic_station or ic_station not in ic_index:\n",
    "            merged.append(r)\n",
    "            continue\n",
    "\n",
    "        # Timestamp perso\n",
    "        t_r = pd.to_datetime(r.get(\"timestamp\"), errors=\"coerce\")\n",
    "        # Si timestamp invalide → on ne fusionne pas\n",
    "        if pd.isna(t_r):\n",
    "            merged.append(r)\n",
    "            continue\n",
    "            # On fusionne InfoClimat uniquement pour octobre\n",
    "        if t_r.month != 10:\n",
    "            merged.append(r)\n",
    "            continue\n",
    "\n",
    "        # Chercher la mesure IC la plus proche\n",
    "        closest = None\n",
    "        min_diff = pd.Timedelta(\"1h\")  # fenêtre max 1h\n",
    "\n",
    "        for ic_r in ic_index[ic_station]:\n",
    "            ts_ic = ic_r.get(\"timestamp\")\n",
    "            if ts_ic is None:\n",
    "                continue\n",
    "\n",
    "            t_ic = pd.to_datetime(ts_ic, errors=\"coerce\")\n",
    "            if pd.isna(t_ic):\n",
    "                continue\n",
    "\n",
    "            diff = abs(t_r - t_ic)\n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                closest = ic_r\n",
    "\n",
    "        # Fusion\n",
    "        if closest:\n",
    "            normal_fields = [\"temperature\", \"humidity\", \"pressure\", \"wind_speed\", \"wind_gust\"]\n",
    "            rain_fields = [\"rain_rate\", \"rain_total\"]\n",
    "\n",
    "            # Champs météo classiques\n",
    "            for f in normal_fields:\n",
    "                if is_missing(r.get(f)) and not is_missing(closest.get(f)):\n",
    "                    r[f] = closest[f]\n",
    "\n",
    "            # Pluie : 0.0 est une valeur valide → on ne remplace que les None\n",
    "            for f in rain_fields:\n",
    "                if is_missing(r.get(f)) and not is_missing(closest.get(f)):\n",
    "                    r[f] = closest[f]\n",
    "\n",
    "        merged.append(r)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PIPELINE STATIONS PERSONNELLES\n",
    "# =====================================================\n",
    "ALL_DOCS = []\n",
    "\n",
    "def process_personal_station(input_file, station_id):\n",
    "    raw = load_json(input_file)\n",
    "    measures = raw if isinstance(raw, list) else raw.get(\"data\", [])\n",
    "    normalized = [normalize_measure(m) for m in measures]\n",
    "    #  FILTRAGE DES LIGNES INVALIDES (sans timestamp)\n",
    "    normalized = [m for m in normalized if m[\"timestamp\"] is not None]\n",
    "    enriched = [enrich_measure(station_id, m) for m in normalized]\n",
    "    ALL_DOCS.extend(enriched)\n",
    "\n",
    "# =====================================================\n",
    "# PIPELINE INFOCLIMAT\n",
    "# =====================================================\n",
    "def process_infoclimat(input_file):\n",
    "    infoclimat_docs = []\n",
    "    raw = load_json(input_file)\n",
    "    # Ajouter les stations au meta\n",
    "    for s in raw.get(\"stations\", []):\n",
    "        STATIONS_META[s[\"id\"]] = {\n",
    "            \"name\": s[\"name\"],\n",
    "            \"lat\": s[\"latitude\"],\n",
    "            \"lon\": s[\"longitude\"],\n",
    "            \"elevation\": s[\"elevation\"],\n",
    "            \"city\": s[\"name\"],\n",
    "            \"hardware\": \"professional\",\n",
    "            \"software\": \"InfoClimat\",\n",
    "            \"source\": \"InfoClimat\"\n",
    "        }\n",
    "\n",
    "    for station_id, measures in raw.get(\"hourly\", {}).items():\n",
    "        measures = [normalize_measure(m) for m in measures if isinstance(m, dict)]\n",
    "        enriched = [enrich_measure(station_id, m) for m in measures]\n",
    "        infoclimat_docs.extend(enriched)\n",
    "\n",
    "    return infoclimat_docs\n",
    "\n",
    "# =====================================================\n",
    "# MAIN\n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"===== PIPELINE DE TRANSFORMATION & FUSION =====\")\n",
    "\n",
    "    # Stations perso\n",
    "    process_personal_station(\"data/la_madeleine.json\", \"ILAMAD25\")\n",
    "    process_personal_station(\"data/ichtegem.json\", \"IICHTE19\")\n",
    "    print(\"=== échantillon IICHTE19 (perso) ===\")\n",
    "    for r in ALL_DOCS:\n",
    "        if r[\"station_id\"] == \"IICHTE19\":\n",
    "            print(r) \n",
    "            break\n",
    "\n",
    "    \n",
    "    # InfoClimat\n",
    "    infoclimat_docs = process_infoclimat(\"data/InfoClimat.json\")\n",
    "\n",
    "    print(\"=== Stations InfoClimat disponibles ===\")\n",
    "    print(sorted({r[\"station_id\"] for r in infoclimat_docs}))\n",
    "    print(\"=== Exemple données InfoClimat pour 07016 ===\")\n",
    "    for r in infoclimat_docs:\n",
    "        if r[\"station_id\"] == \"07015\":\n",
    "            print(r)\n",
    "            break\n",
    "\n",
    "\n",
    "    # Mapping perso → InfoClimat\n",
    "    mapping = {\n",
    "        \"ILAMAD25\": \"07015\",\n",
    "        \"IICHTE19\": \"000R5\"\n",
    "        #\"IICHTE19\": \"07016\"\n",
    "    }\n",
    "    \n",
    "    # Fusion des données InfoClimat dans stations perso\n",
    "    ALL_DOCS[:] = merge_infoclimat(ALL_DOCS, infoclimat_docs, mapping)\n",
    "\n",
    "    # Tests d’intégrité\n",
    "    test_integrity(ALL_DOCS, \"FINAL JSON FUSIONNÉ\")\n",
    "\n",
    "    # Sauvegarde finale\n",
    "    save_json(\"output/final_mongo.json\", ALL_DOCS)\n",
    "    print(f\"\\n FINI — {len(ALL_DOCS)} documents prêts pour MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dcddf-c690-4dab-bcdd-8b47128ff0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
